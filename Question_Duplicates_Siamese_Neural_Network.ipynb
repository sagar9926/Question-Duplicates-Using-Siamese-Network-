{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Duplicates Siamese Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagar9926/Question-Duplicates-Using-Siamese-Network-/blob/main/Question_Duplicates_Siamese_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kmvEZWScJjA"
      },
      "source": [
        "# Question duplicates\n",
        "\n",
        "In this assignment I have explored Siamese networks applied to natural language processing. \n",
        "\n",
        "## Outline\n",
        "\n",
        "- [Overview](#0)\n",
        "- [Part 1: Importing the Data](#1)\n",
        "    - [1.1 Loading in the data](#1.1)\n",
        "    - [1.2 Converting a question to a tensor](#1.2)\n",
        "    - [1.3 Understanding the iterator](#1.3)\n",
        "        - [Exercise 01](#ex01)\n",
        "- [Part 2: Defining the Siamese model](#2)\n",
        "    - [2.1 Understanding Siamese Network](#2.1)\n",
        "        - [Exercise 02](#ex02)\n",
        "    - [2.2 Hard  Negative Mining](#2.2)\n",
        "        - [Exercise 03](#ex03)\n",
        "- [Part 3: Training](#3)\n",
        "    - [3.1 Training the model](#3.1)\n",
        "        - [Exercise 04](#ex04)\n",
        "- [Part 4: Evaluation](#4)\n",
        "    - [4.1 Evaluating your siamese network](#4.1)\n",
        "    - [4.2 Classify](#4.2)\n",
        "        - [Exercise 05](#ex05)\n",
        "- [Part 5: Testing with your own questions](#5)\n",
        "    - [Exercise 06](#ex06)\n",
        "- [On Siamese networks](#6)\n",
        "\n",
        "<a name='0'></a>\n",
        "### Overview\n",
        "In this assignment, concretely you will: \n",
        "\n",
        "- Learn about Siamese networks\n",
        "- Understand how the triplet loss works\n",
        "- Understand how to evaluate accuracy\n",
        "- Use cosine similarity between the model's outputted vectors\n",
        "- Use the data generator to get batches of questions\n",
        "- Predict using your own model\n",
        "\n",
        "By now, you are familiar with trax and know how to make use of classes to define your model. We will start this homework by asking you to preprocess the data the same way you did in the previous assignments. After processing the data you will build a classifier that will allow you to identify whether to questions are the same or not. \n",
        "<img src = \"https://github.com/amanjeetsahu/Natural-Language-Processing-Specialization/raw/d562105e68a0b85012ad3ebbb29b2af6344ad4e5/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%204/meme.png\" style=\"width:550px;height:300px;\"/>\n",
        "\n",
        "\n",
        "You will process the data first and then pad in a similar way you have done in the previous assignment. Your model will take in the two question embeddings, run them through an LSTM, and then compare the outputs of the two sub networks using cosine similarity. Before taking a deep dive into the model, start by importing the data set.\n",
        "\n",
        "\n",
        "<a name='1'></a>\n",
        "# Part 1: Importing the Data\n",
        "<a name='1.1'></a>\n",
        "### 1.1 Loading in the data\n",
        "\n",
        "You will be using the Quora question answer dataset to build a model that could identify similar questions. This is a useful task because you don't want to have several versions of the same question posted. Several times when teaching I end up responding to similar questions on piazza, or on other community forums. This data set has been labeled for you. Run the cell below to import some of the packages you will be using. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdP995LEfAC"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUKitARq6TwU",
        "outputId": "f22034d1-043e-40d5-f009-0df6fa79b4c7"
      },
      "source": [
        "import random\n",
        "import torchtext,torch\n",
        "from torchtext.legacy import data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import random as rnd\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrjbNhjVGNRz",
        "outputId": "119d41d6-92b5-4aec-8031-19f13608d142"
      },
      "source": [
        "print(\"Device : \",device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device :  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlC6lWAEmxK"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzqfhZ9e6sZ_",
        "outputId": "95c90a5d-7fb0-4320-8469-05eef696de1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "s6LUFhsx61-u",
        "outputId": "026c68eb-b1d9-41dc-b5de-af449c038e9a"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Study Decks/Natural Language Processing/questions.csv\"\n",
        "df = pd.read_csv(path)\n",
        "N=len(df)\n",
        "print('Number of question pairs: ', N)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of question pairs:  404351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raC1SXmxFu22",
        "outputId": "a02f9c9c-05e5-4eb1-c8dc-fdb8b5101b42"
      },
      "source": [
        "N_train = 300000\n",
        "N_test  = 10*1024\n",
        "data_train = df[:N_train]\n",
        "data_test  = df[N_train:N_train+N_test]\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
        "\n",
        "td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
        "td_index = [i for i, x in enumerate(td_index) if x] \n",
        "print('number of duplicate questions: ', len(td_index))\n",
        "print('indexes of first ten duplicate questions:', td_index[:10])\n",
        "\n",
        "Q1_train_words = np.array(data_train['question1'][td_index])\n",
        "Q2_train_words = np.array(data_train['question2'][td_index])\n",
        "y_train = np.array([1]*len(Q1_train_words))\n",
        "\n",
        "Q1_test_words = np.array(data_test['question1'])\n",
        "Q2_test_words = np.array(data_test['question2'])\n",
        "y_test  = np.array(data_test['is_duplicate'])\n",
        "\n",
        "print('TRAINING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_train_words[0])\n",
        "print('Question 2: ', Q2_train_words[0], '\\n')\n",
        "print('Question 1: ', Q1_train_words[5])\n",
        "print('Question 2: ', Q2_train_words[5], '\\n')\n",
        "\n",
        "print('TESTING QUESTIONS:\\n')\n",
        "print('Question 1: ', Q1_test_words[0])\n",
        "print('Question 2: ', Q2_test_words[0], '\\n')\n",
        "print('is_duplicate =', y_test[0], '\\n')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: 300000 Test set: 10240\n",
            "number of duplicate questions:  111486\n",
            "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n",
            "TRAINING QUESTIONS:\n",
            "\n",
            "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
            "\n",
            "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
            "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
            "\n",
            "TESTING QUESTIONS:\n",
            "\n",
            "Question 1:  How do I prepare for interviews for cse?\n",
            "Question 2:  What is the best way to prepare for cse? \n",
            "\n",
            "is_duplicate = 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ugVX5FjLDy",
        "outputId": "c7b9f352-a775-4383-a97c-13c1d26540e8"
      },
      "source": [
        "#create arrays\n",
        "Q1_train = np.empty_like(Q1_train_words)\n",
        "Q2_train = np.empty_like(Q2_train_words)\n",
        "\n",
        "Q1_test = np.empty_like(Q1_test_words)\n",
        "Q2_test = np.empty_like(Q2_test_words)\n",
        "\n",
        "# Building the vocabulary with the train set         (this might take a minute)\n",
        "from collections import defaultdict\n",
        "\n",
        "vocab = defaultdict(lambda: 0)\n",
        "vocab['<PAD>'] = 1\n",
        "\n",
        "for idx in range(len(Q1_train_words)):\n",
        "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
        "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
        "    q = Q1_train[idx] + Q2_train[idx]\n",
        "    for word in q:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab) + 1\n",
        "print('The length of the vocabulary is: ', len(vocab))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is:  36342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXsYlxQVjbVH"
      },
      "source": [
        "for idx in range(len(Q1_test_words)): \n",
        "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
        "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPdHV5TtjjB1",
        "outputId": "8e1947ec-25a8-492c-bb2b-e7bf3f660a99"
      },
      "source": [
        "# Converting questions to array of integers\n",
        "for i in range(len(Q1_train)):\n",
        "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
        "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
        "\n",
        "        \n",
        "for i in range(len(Q1_test)):\n",
        "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
        "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]\n",
        "\n",
        "print('first question in the train set:\\n')\n",
        "print(Q1_train_words[0], '\\n') \n",
        "print('encoded version:')\n",
        "print(Q1_train[0],'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test_words[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(Q1_test[0]) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "How do I prepare for interviews for cse? \n",
            "\n",
            "encoded version:\n",
            "[32, 38, 4, 107, 65, 1015, 65, 11522, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kSx4Rqki_Bk",
        "outputId": "5debd441-0e76-4774-dcf2-a46242c51376"
      },
      "source": [
        "# Splitting the data\n",
        "cut_off = int(len(Q1_train)*.8)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
        "print('Number of duplicate questions: ', len(Q1_train))\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicate questions:  111486\n",
            "The length of the training set is:   89188\n",
            "The length of the validation set is:  22298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpgdpgDLRJ54"
      },
      "source": [
        "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: data_generator\n",
        "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
        "    \"\"\"Generator function that yields batches of data\n",
        "\n",
        "    Args:\n",
        "        Q1 (list): List of transformed (to tensor) questions.\n",
        "        Q2 (list): List of transformed (to tensor) questions.\n",
        "        batch_size (int): Number of elements per batch.\n",
        "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
        "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
        "    Yields:\n",
        "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
        "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
        "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
        "    \"\"\"\n",
        "\n",
        "    input1 = []\n",
        "    input2 = []\n",
        "    idx = 0\n",
        "    len_q = len(Q1)\n",
        "    question_indexes = [*range(len_q)]\n",
        "    \n",
        "    if shuffle:\n",
        "        rnd.shuffle(question_indexes)\n",
        "    \n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    while True:\n",
        "        if idx >= len_q:\n",
        "            # if idx is greater than or equal to len_q, set idx accordingly \n",
        "            # (Hint: look at the instructions above)\n",
        "            idx = 0\n",
        "            # shuffle to get random batches if shuffle is set to True\n",
        "            if shuffle:\n",
        "                rnd.shuffle(question_indexes)\n",
        "        \n",
        "        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
        "        q1 = Q1[question_indexes[idx]]\n",
        "        q2 = Q2[question_indexes[idx]]\n",
        "        \n",
        "        # increment idx by 1\n",
        "        idx += 1\n",
        "        # append q1\n",
        "        input1.append(q1)\n",
        "        # append q2\n",
        "        input2.append(q2)\n",
        "        if len(input1) == batch_size:\n",
        "            # determine max_len as the longest question in input1 & input 2\n",
        "            # Hint: use the `max` function. \n",
        "            # take max of input1 & input2 and then max out of the two of them.\n",
        "            max_len = max([len(x) for x in input1] + [len(x) for x in input2])\n",
        "            # pad to power-of-2 (Hint: look at the instructions above)\n",
        "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
        "            b1 = []\n",
        "            b2 = []\n",
        "            for q1, q2 in zip(input1, input2):\n",
        "                # add [pad] to q1 until it reaches max_len\n",
        "                q1 = q1 + [pad]*(max_len - len(q1))\n",
        "                # add [pad] to q2 until it reaches max_len\n",
        "                q2 = q2 + [pad]*(max_len - len(q2)) \n",
        "                # append q1\n",
        "                b1.append(torch.tensor(q1))\n",
        "                # append q2\n",
        "                b2.append(torch.tensor(q2))\n",
        "            # use b1 and b2\n",
        "            \n",
        "            yield torch.stack([*b1]),torch.stack([*b2])\n",
        "    ### END CODE HERE ###\n",
        "            # reset the batches\n",
        "            input1, input2 = [], []  # reset the batches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_uvHF-i0SP",
        "outputId": "eb0d7118-36a4-40c3-b076-db9f206471f4"
      },
      "source": [
        "batch_size = 4\n",
        "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
        "print(\"First questions  : \",'\\n', res1, '\\n')\n",
        "print(\"Second questions : \",'\\n', res2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First questions  :  \n",
            " tensor([[   32,     4,    33,   331,    43,   230,  3717,    21,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1],\n",
            "        [   30,   156,    78,   317,   307,   617,    11,  2121,    21,     1,\n",
            "             1,     1,     1,     1,     1,     1],\n",
            "        [  244,   156,    78, 20106,  1759,   127,    56,   792,    21,     1,\n",
            "             1,     1,     1,     1,     1,     1],\n",
            "        [  219,   138,   473,   165,  2618,   267,  1596,  6917,    21,     1,\n",
            "             1,     1,     1,     1,     1,     1]]) \n",
            "\n",
            "Second questions :  \n",
            " tensor([[  30,   33,    4,   38,   39,  331,   43,  230, 1212,   21,    1,    1,\n",
            "            1,    1,    1,    1],\n",
            "        [  30,  156,   78,  317,  307, 2121,   11,  617,   21,    1,    1,    1,\n",
            "            1,    1,    1,    1],\n",
            "        [ 244,  156,   78,  134, 2131, 1759,  131,   56,  792,   21,    1,    1,\n",
            "            1,    1,    1,    1],\n",
            "        [ 219,  138,  473,  165, 2618,  267, 1438, 1596, 6917,   21,    1,    1,\n",
            "            1,    1,    1,    1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHFF_8L9i0oZ"
      },
      "source": [
        "# Model\n",
        "\n",
        "## Siamese Neural Network\n",
        "\n",
        "Siamese neural network is a class of neural network architectures that contain two or more identical sub networks. identical here means they have the same configuration with the same parameters and weights. Parameter updating is mirrored across both sub networks.It is used find the similarity of the inputs by comparing its feature vectors.\n",
        "\n",
        "For more details check this blog : https://innovationincubator.com/siamaese-neural-network-with-paytorch-code-example/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7__wkYqtUWK8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# https://towardsdatascience.com/lstms-in-pytorch-528b0440244#:~:text=The%20input%20to%20the%20LSTM,batch_size%2C%20sequence_length%2C%20hidden_size)%20.\n",
        "\n",
        "# https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm#:~:text=In%20Pytorch%2C%20the%20output%20parameter,LSTM%20stack%20in%20every%20layer.\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           batch_first=True)\n",
        "                           \n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward_once(self, text):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(embedded)\n",
        "        \n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "\n",
        "        packed_output = self.fc(packed_output)\n",
        "        packed_output = torch.mean(packed_output,axis = 1 )\n",
        "        packed_output = packed_output / torch.norm(packed_output,dim = 1,keepdim= True)\n",
        "        #packed_output = (packed_output - packed_output.mean(axis = 1,keepdim = True))/packed_output.std(axis = 1,keepdim = True,unbiased=False)\n",
        "        return packed_output\n",
        "        \n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_once(input1)\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfS9GI_gWLmM"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(vocab)\n",
        "embedding_dim = 128\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 3\n",
        "num_layers = 1\n",
        "#dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = SiameseNetwork(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers)\n",
        "model = model.to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp2FPAC1nYY8",
        "outputId": "3c67b05f-44b0-47f3-9b5e-ae9fa1ff28a1"
      },
      "source": [
        "[p.shape for p in model.parameters()]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([41789, 128]),\n",
              " torch.Size([400, 128]),\n",
              " torch.Size([400, 100]),\n",
              " torch.Size([400]),\n",
              " torch.Size([400]),\n",
              " torch.Size([100, 100]),\n",
              " torch.Size([100])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bv0x_pnWQSO",
        "outputId": "63e8aa53-cf1f-4c78-d9cb-cfcb6ee8199a"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SiameseNetwork(\n",
            "  (embedding): Embedding(41789, 128)\n",
            "  (encoder): LSTM(128, 100, batch_first=True)\n",
            "  (fc): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n",
            "The model has 5,451,092 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2jReutalKGr",
        "outputId": "8997825b-8de8-4f2d-c0ff-10e56a150e6f"
      },
      "source": [
        "batch_size = 256\n",
        "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
        "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n",
        "print('train_Q1.shape ', train_Q1.shape)\n",
        "print('val_Q1.shape   ', val_Q1.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_Q1.shape  (89188,)\n",
            "val_Q1.shape    (22298,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O8EuCxmuASp"
      },
      "source": [
        "# Triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPvABnsVrLVS"
      },
      "source": [
        "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: TripletLossFn\n",
        "def TripletLossFn(v1, v2, margin=torch.tensor([0.5])):\n",
        "    \"\"\"Custom Loss function.\n",
        "\n",
        "    Args:\n",
        "        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
        "        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
        "        margin (float, optional): Desired margin. Defaults to 0.25.\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Triplet Loss.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    \n",
        "    # use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)\n",
        "    #v1 = v1 / torch.norm(v1,dim = 1,keepdim= True)\n",
        "    #v2 = v2 / torch.norm(v2,dim = 1,keepdim= True)\n",
        "    #print(\"v1 : \",v1)\n",
        "    #print(\"v2 :\",v2)\n",
        "    scores = torch.mm(v1,v2.T)  # pairwise cosine sim\n",
        "    #print(\"scores : \",scores)\n",
        "    # calculate new batch size\n",
        "    batch_size = len(scores)\n",
        "    # use fastnp to grab all postive `diagonal` entries in `scores`\n",
        "    positive = torch.diag(scores)  # the positive ones (duplicates)\n",
        "    \n",
        "    # multiply `fastnp.eye(batch_size)` with 2.0 and subtract it out of `scores`\n",
        "    negative_without_positive = scores - 2.0 * torch.eye(batch_size,device = device)\n",
        "    \n",
        "    # take the row by row `max` of `negative_without_positive`. \n",
        "    # Hint: negative_without_positive.max(axis = [?])  \n",
        "    closest_negative = negative_without_positive.max(axis=1)\n",
        "    #print(\"closest_negative : \",closest_negative)\n",
        "    # subtract `fastnp.eye(batch_size)` out of 1.0 and do element-wise multiplication with `scores`\n",
        "    negative_zero_on_duplicate = scores * (1.0 - torch.eye(batch_size,device = device))\n",
        "    # use `fastnp.sum` on `negative_zero_on_duplicate` for `axis=1` and divide it by `(batch_size - 1)` \n",
        "    mean_negative = torch.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
        "    #print(\"mean_negative \",mean_negative)\n",
        "    # compute `fastnp.maximum` among 0.0 and `A`\n",
        "    # A = subtract `positive` from `margin` and add `closest_negative` \n",
        "    triplet_loss1 = torch.maximum(torch.tensor([0.0]).cuda(), margin.cuda() - positive + closest_negative.values)\n",
        "    \n",
        "    # compute `fastnp.maximum` among 0.0 and `B`\n",
        "    # B = subtract `positive` from `margin` and add `mean_negative`\n",
        "    triplet_loss2 = torch.maximum(torch.tensor([0.0]).cuda(), margin.cuda() - positive + mean_negative)\n",
        "    # add the two losses together and take the `fastnp.mean` of it\n",
        "    triplet_loss = torch.mean(triplet_loss1 + triplet_loss2)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    #print(\"triplet_loss : \",triplet_loss)\n",
        "    return triplet_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUvotTLhC3Fj",
        "outputId": "89326672-0526-4a2f-ae65-7feda9e0cf98"
      },
      "source": [
        "v1 = torch.tensor(np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887],[0.8617891 , 0.43543534, 0.21297887]])).cuda()\n",
        "v2 = torch.tensor(np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887],[0.8617891 , 0.43543534, 0.21297887]])).cuda()\n",
        "print(\"Triplet Loss:\", TripletLossFn(v2,v1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Triplet Loss: tensor(0.8774, device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z5LalBaDbMG"
      },
      "source": [
        "# TrainingLoop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlIvfdhDDGh_"
      },
      "source": [
        "def train(train_generator,model,optimizer,criterion,epochs = 100):\n",
        "    counter = []\n",
        "    loss_history = [] \n",
        "    iteration_number= 0\n",
        "    best_loss = 10000\n",
        "    PATH = '/content/best-model.pt'\n",
        "    for epoch in range(epochs):\n",
        "        for i, batch in enumerate(train_generator,0):\n",
        "            batch_Q1, batch_Q2  = batch\n",
        "            batch_Q1, batch_Q2  = batch_Q1.cuda(), batch_Q2.cuda() \n",
        "            optimizer.zero_grad()\n",
        "            output1,output2 = model(batch_Q1, batch_Q2)\n",
        "            loss_contrastive = criterion(output1,output2)\n",
        "\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if loss_contrastive < best_loss:\n",
        "              best_loss = loss_contrastive\n",
        "              print(\"Save model... best loss = \",best_loss.item())\n",
        "              torch.save(model.state_dict(), PATH)\n",
        "            if (i+1) % (89188//batch_size)  == 0 : \n",
        "                \n",
        "                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive))\n",
        "                break\n",
        "\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSQcgmDnFj0H",
        "outputId": "56d9b7b0-51ca-4d06-a5f6-0c3dc78fadc6"
      },
      "source": [
        "# Train the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "criterion = TripletLossFn\n",
        "model = train(train_generator,model,optimizer,criterion)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save model... best loss =  0.9958070516586304\n",
            "Save model... best loss =  0.9918943047523499\n",
            "Save model... best loss =  0.9697502255439758\n",
            "Save model... best loss =  0.8653439283370972\n",
            "Save model... best loss =  0.8480695486068726\n",
            "Save model... best loss =  0.8233498930931091\n",
            "Save model... best loss =  0.7832368016242981\n",
            "Save model... best loss =  0.7467554211616516\n",
            "Save model... best loss =  0.7076646089553833\n",
            "Save model... best loss =  0.6916126012802124\n",
            "Save model... best loss =  0.6892021894454956\n",
            "Save model... best loss =  0.6608090400695801\n",
            "Save model... best loss =  0.6399219632148743\n",
            "Save model... best loss =  0.6276798844337463\n",
            "Save model... best loss =  0.6135058403015137\n",
            "Save model... best loss =  0.6064757704734802\n",
            "Save model... best loss =  0.6018864512443542\n",
            "Save model... best loss =  0.5986359119415283\n",
            "Save model... best loss =  0.583355724811554\n",
            "Save model... best loss =  0.5597968101501465\n",
            "Save model... best loss =  0.55203777551651\n",
            "Save model... best loss =  0.5486853718757629\n",
            "Save model... best loss =  0.5383610725402832\n",
            "Save model... best loss =  0.5347698926925659\n",
            "Save model... best loss =  0.5189296007156372\n",
            "Save model... best loss =  0.5060456991195679\n",
            "Save model... best loss =  0.49154138565063477\n",
            "Save model... best loss =  0.48718369007110596\n",
            "Save model... best loss =  0.48099592328071594\n",
            "Save model... best loss =  0.4708913564682007\n",
            "Save model... best loss =  0.4694109559059143\n",
            "Save model... best loss =  0.45419949293136597\n",
            "Save model... best loss =  0.43428778648376465\n",
            "Save model... best loss =  0.4207439720630646\n",
            "Save model... best loss =  0.42037782073020935\n",
            "Save model... best loss =  0.41159331798553467\n",
            "Save model... best loss =  0.40250226855278015\n",
            "Save model... best loss =  0.3689724802970886\n",
            "Save model... best loss =  0.35555505752563477\n",
            "Save model... best loss =  0.33326804637908936\n",
            "Save model... best loss =  0.32527628540992737\n",
            "Save model... best loss =  0.3172929286956787\n",
            "Save model... best loss =  0.30030107498168945\n",
            "Save model... best loss =  0.2995140552520752\n",
            "Save model... best loss =  0.2895742654800415\n",
            "Save model... best loss =  0.27696722745895386\n",
            "Save model... best loss =  0.2574084997177124\n",
            "Save model... best loss =  0.2218235284090042\n",
            "Save model... best loss =  0.21856528520584106\n",
            "Save model... best loss =  0.2105288803577423\n",
            "Save model... best loss =  0.2035476267337799\n",
            "Epoch number 0\n",
            " Current loss 0.2528953552246094\n",
            "\n",
            "Save model... best loss =  0.19560551643371582\n",
            "Save model... best loss =  0.18452821671962738\n",
            "Save model... best loss =  0.178939089179039\n",
            "Save model... best loss =  0.1739867925643921\n",
            "Save model... best loss =  0.16854333877563477\n",
            "Save model... best loss =  0.15646560490131378\n",
            "Save model... best loss =  0.15436196327209473\n",
            "Save model... best loss =  0.14604038000106812\n",
            "Save model... best loss =  0.14182902872562408\n",
            "Epoch number 1\n",
            " Current loss 0.17288458347320557\n",
            "\n",
            "Save model... best loss =  0.12624530494213104\n",
            "Save model... best loss =  0.12367058545351028\n",
            "Save model... best loss =  0.121909499168396\n",
            "Save model... best loss =  0.11526134610176086\n",
            "Save model... best loss =  0.10981279611587524\n",
            "Save model... best loss =  0.1086290255188942\n",
            "Epoch number 2\n",
            " Current loss 0.1382160782814026\n",
            "\n",
            "Save model... best loss =  0.1015794575214386\n",
            "Save model... best loss =  0.10122421383857727\n",
            "Save model... best loss =  0.09387927502393723\n",
            "Save model... best loss =  0.08828727155923843\n",
            "Epoch number 3\n",
            " Current loss 0.14608287811279297\n",
            "\n",
            "Save model... best loss =  0.08696606010198593\n",
            "Epoch number 4\n",
            " Current loss 0.1103912740945816\n",
            "\n",
            "Save model... best loss =  0.08611246943473816\n",
            "Save model... best loss =  0.08398807048797607\n",
            "Save model... best loss =  0.08224736154079437\n",
            "Epoch number 5\n",
            " Current loss 0.11887183040380478\n",
            "\n",
            "Save model... best loss =  0.07864274084568024\n",
            "Save model... best loss =  0.07612936198711395\n",
            "Epoch number 6\n",
            " Current loss 0.1227383092045784\n",
            "\n",
            "Save model... best loss =  0.07591675221920013\n",
            "Epoch number 7\n",
            " Current loss 0.1347464621067047\n",
            "\n",
            "Save model... best loss =  0.07137560099363327\n",
            "Save model... best loss =  0.06611276417970657\n",
            "Epoch number 8\n",
            " Current loss 0.09477681666612625\n",
            "\n",
            "Save model... best loss =  0.062345266342163086\n",
            "Epoch number 9\n",
            " Current loss 0.12560607492923737\n",
            "\n",
            "Save model... best loss =  0.05734512209892273\n",
            "Epoch number 10\n",
            " Current loss 0.11827729642391205\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 0.10090579837560654\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 0.10935616493225098\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 0.09280899167060852\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 0.09812123328447342\n",
            "\n",
            "Save model... best loss =  0.05395656079053879\n",
            "Epoch number 15\n",
            " Current loss 0.09496735036373138\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 0.11377119272947311\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 0.09620897471904755\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 0.09398332983255386\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 0.08201748877763748\n",
            "\n",
            "Epoch number 20\n",
            " Current loss 0.10350437462329865\n",
            "\n",
            "Save model... best loss =  0.04265433922410011\n",
            "Epoch number 21\n",
            " Current loss 0.09671787917613983\n",
            "\n",
            "Epoch number 22\n",
            " Current loss 0.0705932155251503\n",
            "\n",
            "Epoch number 23\n",
            " Current loss 0.09216906130313873\n",
            "\n",
            "Epoch number 24\n",
            " Current loss 0.06719131767749786\n",
            "\n",
            "Epoch number 25\n",
            " Current loss 0.11566528677940369\n",
            "\n",
            "Epoch number 26\n",
            " Current loss 0.07722483575344086\n",
            "\n",
            "Epoch number 27\n",
            " Current loss 0.09841714799404144\n",
            "\n",
            "Epoch number 28\n",
            " Current loss 0.11332175135612488\n",
            "\n",
            "Epoch number 29\n",
            " Current loss 0.06969743221998215\n",
            "\n",
            "Epoch number 30\n",
            " Current loss 0.09868906438350677\n",
            "\n",
            "Epoch number 31\n",
            " Current loss 0.08032704889774323\n",
            "\n",
            "Epoch number 32\n",
            " Current loss 0.09379351139068604\n",
            "\n",
            "Epoch number 33\n",
            " Current loss 0.10339054465293884\n",
            "\n",
            "Epoch number 34\n",
            " Current loss 0.09034454077482224\n",
            "\n",
            "Epoch number 35\n",
            " Current loss 0.08335628360509872\n",
            "\n",
            "Epoch number 36\n",
            " Current loss 0.07542084157466888\n",
            "\n",
            "Epoch number 37\n",
            " Current loss 0.09210698306560516\n",
            "\n",
            "Epoch number 38\n",
            " Current loss 0.10199637711048126\n",
            "\n",
            "Epoch number 39\n",
            " Current loss 0.09728708118200302\n",
            "\n",
            "Epoch number 40\n",
            " Current loss 0.11815854161977768\n",
            "\n",
            "Epoch number 41\n",
            " Current loss 0.1113239973783493\n",
            "\n",
            "Epoch number 42\n",
            " Current loss 0.09692101925611496\n",
            "\n",
            "Epoch number 43\n",
            " Current loss 0.09198407828807831\n",
            "\n",
            "Epoch number 44\n",
            " Current loss 0.07310106605291367\n",
            "\n",
            "Epoch number 45\n",
            " Current loss 0.09975408017635345\n",
            "\n",
            "Epoch number 46\n",
            " Current loss 0.09623251855373383\n",
            "\n",
            "Save model... best loss =  0.04093354940414429\n",
            "Epoch number 47\n",
            " Current loss 0.056715767830610275\n",
            "\n",
            "Epoch number 48\n",
            " Current loss 0.1077285185456276\n",
            "\n",
            "Epoch number 49\n",
            " Current loss 0.10991789400577545\n",
            "\n",
            "Epoch number 50\n",
            " Current loss 0.07417050749063492\n",
            "\n",
            "Epoch number 51\n",
            " Current loss 0.11157821863889694\n",
            "\n",
            "Epoch number 52\n",
            " Current loss 0.09748522937297821\n",
            "\n",
            "Epoch number 53\n",
            " Current loss 0.09705494344234467\n",
            "\n",
            "Epoch number 54\n",
            " Current loss 0.10564243793487549\n",
            "\n",
            "Epoch number 55\n",
            " Current loss 0.11333070695400238\n",
            "\n",
            "Epoch number 56\n",
            " Current loss 0.11227643489837646\n",
            "\n",
            "Epoch number 57\n",
            " Current loss 0.10035096108913422\n",
            "\n",
            "Epoch number 58\n",
            " Current loss 0.10261423140764236\n",
            "\n",
            "Epoch number 59\n",
            " Current loss 0.10336777567863464\n",
            "\n",
            "Epoch number 60\n",
            " Current loss 0.09969563037157059\n",
            "\n",
            "Epoch number 61\n",
            " Current loss 0.08325094729661942\n",
            "\n",
            "Epoch number 62\n",
            " Current loss 0.10298009216785431\n",
            "\n",
            "Epoch number 63\n",
            " Current loss 0.08500668406486511\n",
            "\n",
            "Epoch number 64\n",
            " Current loss 0.09019149094820023\n",
            "\n",
            "Epoch number 65\n",
            " Current loss 0.09742673486471176\n",
            "\n",
            "Epoch number 66\n",
            " Current loss 0.08355646580457687\n",
            "\n",
            "Epoch number 67\n",
            " Current loss 0.08959642797708511\n",
            "\n",
            "Epoch number 68\n",
            " Current loss 0.10096856951713562\n",
            "\n",
            "Epoch number 69\n",
            " Current loss 0.0829731673002243\n",
            "\n",
            "Epoch number 70\n",
            " Current loss 0.08515411615371704\n",
            "\n",
            "Epoch number 71\n",
            " Current loss 0.0867038369178772\n",
            "\n",
            "Epoch number 72\n",
            " Current loss 0.1118641048669815\n",
            "\n",
            "Epoch number 73\n",
            " Current loss 0.06755080819129944\n",
            "\n",
            "Epoch number 74\n",
            " Current loss 0.09230592846870422\n",
            "\n",
            "Epoch number 75\n",
            " Current loss 0.12362444400787354\n",
            "\n",
            "Epoch number 76\n",
            " Current loss 0.09555137157440186\n",
            "\n",
            "Epoch number 77\n",
            " Current loss 0.09409941732883453\n",
            "\n",
            "Epoch number 78\n",
            " Current loss 0.08598595857620239\n",
            "\n",
            "Epoch number 79\n",
            " Current loss 0.10068808495998383\n",
            "\n",
            "Epoch number 80\n",
            " Current loss 0.08312129229307175\n",
            "\n",
            "Epoch number 81\n",
            " Current loss 0.09367454051971436\n",
            "\n",
            "Epoch number 82\n",
            " Current loss 0.08861538767814636\n",
            "\n",
            "Epoch number 83\n",
            " Current loss 0.11003158241510391\n",
            "\n",
            "Epoch number 84\n",
            " Current loss 0.08498461544513702\n",
            "\n",
            "Epoch number 85\n",
            " Current loss 0.10648928582668304\n",
            "\n",
            "Epoch number 86\n",
            " Current loss 0.07335612922906876\n",
            "\n",
            "Epoch number 87\n",
            " Current loss 0.08627605438232422\n",
            "\n",
            "Epoch number 88\n",
            " Current loss 0.09358911216259003\n",
            "\n",
            "Epoch number 89\n",
            " Current loss 0.08095628023147583\n",
            "\n",
            "Epoch number 90\n",
            " Current loss 0.10192421078681946\n",
            "\n",
            "Epoch number 91\n",
            " Current loss 0.10136592388153076\n",
            "\n",
            "Epoch number 92\n",
            " Current loss 0.08221247792243958\n",
            "\n",
            "Epoch number 93\n",
            " Current loss 0.08385365456342697\n",
            "\n",
            "Epoch number 94\n",
            " Current loss 0.0959136039018631\n",
            "\n",
            "Epoch number 95\n",
            " Current loss 0.11999829113483429\n",
            "\n",
            "Epoch number 96\n",
            " Current loss 0.09627282619476318\n",
            "\n",
            "Epoch number 97\n",
            " Current loss 0.08725842088460922\n",
            "\n",
            "Epoch number 98\n",
            " Current loss 0.10618884861469269\n",
            "\n",
            "Epoch number 99\n",
            " Current loss 0.09464776515960693\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44LjzKm0-RzP",
        "outputId": "69e7851a-a10c-4c19-f57e-69b33d644992"
      },
      "source": [
        "PATH = '/content/best-model.pt'\n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apHpPNBPK_5p"
      },
      "source": [
        "\n",
        "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
        "    \"\"\"Function to test the accuracy of the model.\n",
        "\n",
        "    Args:\n",
        "        test_Q1 (numpy.ndarray): Array of Q1 questions.\n",
        "        test_Q2 (numpy.ndarray): Array of Q2 questions.\n",
        "        y (numpy.ndarray): Array of actual target.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model.\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    for i in range(0, len(test_Q1), batch_size):\n",
        "        # Call the data generator (built in Ex 01) with shuffle=False using next()\n",
        "        # use batch size chuncks of questions as Q1 & Q2 arguments of the data generator. e.g x[i:i + batch_size]\n",
        "        # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
        "        q1, q2 = next(data_generator(test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\n",
        "        # use batch size chuncks of actual output targets (same syntax as example above)\n",
        "        y_test = y[i:i + batch_size]\n",
        "        # Call the model\n",
        "        v1, v2 = model(q1, q2)\n",
        "        v1 = v1.detach().numpy()\n",
        "        v2 = v2.detach().numpy()\n",
        "        \n",
        "        for j in range(batch_size):\n",
        "            # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n",
        "            # don't forget to transpose the second argument\n",
        "            d = np.dot(v1[j], v2[j].T)\n",
        "            # is d greater than the threshold?\n",
        "            res = d > threshold\n",
        "            # increment accurancy if y_test is equal `res`\n",
        "            accuracy += (y_test[j] == res)\n",
        "    # compute accuracy using accuracy and total length of test questions\n",
        "    accuracy = accuracy / len(test_Q1)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpSDomyPLLOe",
        "outputId": "6627f46d-ea37-468d-b50a-80f273ad2fc0"
      },
      "source": [
        "# this takes around 1 minute\n",
        "accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model.to('cpu'), vocab, batch_size = 512) \n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.75107421875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIGK5voS-06N"
      },
      "source": [
        "#Accuracy 0.6232421875"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsnh6vo1SxaJ"
      },
      "source": [
        "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "# GRADED FUNCTION: predict\n",
        "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=True):\n",
        "    \"\"\"Function for predicting if two questions are duplicates.\n",
        "\n",
        "    Args:\n",
        "        question1 (str): First question.\n",
        "        question2 (str): Second question.\n",
        "        threshold (float): Desired threshold.\n",
        "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
        "        vocab (collections.defaultdict): The vocabulary used.\n",
        "        data_generator (function): Data generator function. Defaults to data_generator.\n",
        "        verbose (bool, optional): If the results should be printed out. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the questions are duplicates, False otherwise.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
        "    # use `nltk` word tokenize function to tokenize\n",
        "    q1 = nltk.word_tokenize(question1)  # tokenize\n",
        "    q2 = nltk.word_tokenize(question2)  # tokenize\n",
        "    Q1, Q2 = [], []\n",
        "    for word in q1:  # encode q1\n",
        "        # increment by checking the 'word' index in `vocab`\n",
        "        Q1 += [vocab[word]]\n",
        "    for word in q2:  # encode q2\n",
        "        # increment by checking the 'word' index in `vocab`\n",
        "        Q2 += [vocab[word]]\n",
        "        \n",
        "    # Call the data generator (built in Ex 01) using next()\n",
        "    # pass [Q1] & [Q2] as Q1 & Q2 arguments of the data generator. Set batch size as 1\n",
        "    # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
        "    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n",
        "    # Call the model\n",
        "    v1, v2 = model(Q1, Q2)\n",
        "    # take dot product to compute cos similarity of each pair of entries, v1, v2\n",
        "    # don't forget to transpose the second argument\n",
        "    d = np.dot(v1[0].detach().numpy(), v2[0].detach().numpy().T)\n",
        "    # is d greater than the threshold?\n",
        "    res = d > threshold\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    if(verbose):\n",
        "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
        "        print(\"d   = \", d)\n",
        "        print(\"res = \", res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtFy-IlL1YyI",
        "outputId": "3b3a3401-49b1-4664-9326-879e45aba58b"
      },
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  tensor([[585,  76,   4,  46,  53,  21,   1,   1]]) \n",
            "Q2  =  tensor([[ 585,   33,    4,   46,   53, 7287,   21,    1]])\n",
            "d   =  0.71987504\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yx0Jv7J3eRH",
        "outputId": "55678db6-f6c8-46ae-d533-cd5df47c1617"
      },
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"Do they enjoy eating the dessert?\"\n",
        "question2 = \"Do they like hiking in the desert?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  tensor([[  443,  1145,  3158,  1169,    78, 29071,    21,     1]]) \n",
            "Q2  =  tensor([[  443,  1145,    60, 15323,    28,    78,  7438,    21]])\n",
            "d   =  -0.09125066\n",
            "res =  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01SneQFR5hxa",
        "outputId": "6940ed0e-401f-4e3e-fa52-21edd8f4a7cc"
      },
      "source": [
        "# Feel free to try with your own questions\n",
        "question1 = \"What is your name?\"\n",
        "question2 = \"Can you tell me your name?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  tensor([[  30,  156,   56, 1377,   21,    1,    1,    1]]) \n",
            "Q2  =  tensor([[ 219,   53, 1593,   20,   56, 1377,   21,    1]])\n",
            "d   =  0.7301646\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTzookwf590L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577352ae-6c3f-4a19-875e-67fc9b7dc109"
      },
      "source": [
        "# Feel free to try with your own questions\n",
        "for index in range(20):\n",
        "  question1 = Q1_test_words[index]\n",
        "  question2 = Q2_test_words[index]\n",
        "\n",
        "  print(\"Question 1 :\",question1)\n",
        "  print(\"Question 2 :\",question2)\n",
        "  print(\"\")\n",
        "  # 1 means it is duplicated, 0 otherwise\n",
        "  print(\"Are these questions Similar : \",predict(question1 , question2, 0.7, model, vocab, verbose=False))\n",
        "  print(\"\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question 1 : How do I prepare for interviews for cse?\n",
            "Question 2 : What is the best way to prepare for cse?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : What is the best bicycle to buy under 10k?\n",
            "Question 2 : Which is the best bike in in dia to buy in INR 10k?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : How do I become Mutual funds distributer for all company mutual funds?\n",
            "Question 2 : How do I become mutual funds distributor for all company mutual funds?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : Will this relationship work?\n",
            "Question 2 : Relationship: Will this relationship work?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : How does Brexit affect India?\n",
            "Question 2 : Will the GBP/AUD be affected by Brexit?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : Is Intel HD graphics card 5500 greater than Geforce 820M 2GB NVIDIA graphics card?\n",
            "Question 2 : What is the difference between the Nvidia GeForce 820M and the GeForce GT 820M graphics card?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : What are some SAAS ideas?\n",
            "Question 2 : What is SaaS?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : Which is the best digital photo frame?\n",
            "Question 2 : What are the best 12-inch digital photo frames?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : What is the best and very helpful project in IT by college students?\n",
            "Question 2 : What are the ways by which College of Engineering Trivandrum can come up to a standard like Stanford, given the fact that it receives very competitive students?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : Why do some men pay for sex?\n",
            "Question 2 : Why do men pay for sex?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : What are the best places to visit in Kerala?\n",
            "Question 2 : What all places can one visit on a two day trip in Kerala, India?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : What animal grows to the size of their container?\n",
            "Question 2 : What is the largest size animal a hawk will take?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : What are some recent good Hindi rock songs to sing on stage?\n",
            "Question 2 : What are some Hindi songs that I can sing on stage without any background music and it would sound good?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : How can linkedln help me in finding internship?\n",
            "Question 2 : Should we expect an alien life forms to be similiar to us due to convergent evolution?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : Are the professional athletes overpaid?\n",
            "Question 2 : Do you think professional athletes are overpaid?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : How do I control emotions and reactions in nervousness?\n",
            "Question 2 : How can I control my emotions?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : What is the QuickBooks Hosting Support Number?\n",
            "Question 2 : Which is the best QuickBooks proadvisor tech support number?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n",
            "Question 1 : If ur bf of 3yrs says he doesnt knw y he kips lovin u everydai bt u deserve a complete man tho. What should be ur reply?\n",
            "Question 2 : Is it a big sin if I am not yet married. I am in my 30s, female living in India?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : What are the benefits of a delta wing?\n",
            "Question 2 : What are the advantages a delta wing has over swept wing?\n",
            "\n",
            "Are these questions Similar :  False\n",
            "\n",
            "Question 1 : Why do we study English?\n",
            "Question 2 : Why do I study English?\n",
            "\n",
            "Are these questions Similar :  True\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}